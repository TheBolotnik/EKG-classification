from __future__ import annotations
import os
import sys
import glob
import subprocess
import pandas as pd
import wfdb
import numpy as np
from scipy.stats import skew, kurtosis

from src.config import resolve_base_path
from src.dataio import load_metadata, ensure_files_exist
from src.features import scp_to_superclass, build_features
from src.model import balance_undersample, train_xgb, save_model, load_model
from src.labels import to_russian  # ‚Üê –¥–æ–±–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç –Ω–∞–≤–µ—Ä—Ö—É —Ä—è–¥–æ–º —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏


ROOT = os.path.abspath(os.path.dirname(__file__))
SRC_DIR = os.path.join(ROOT, "src")
if SRC_DIR not in sys.path:
    sys.path.insert(0, SRC_DIR)


def _first_record_path_from_csv(base: str) -> str | None:
    import pandas as pd, os
    csv_path = os.path.join(base, "ptbxl_database.csv")
    if not os.path.isfile(csv_path):
        return None
    db = pd.read_csv(csv_path)
    for rel in db["filename_lr"].tolist():
        hea = os.path.join(base, f"{rel}.hea")
        dat = os.path.join(base, f"{rel}.dat")
        if os.path.isfile(hea) and os.path.isfile(dat):
            return os.path.join(base, rel)  # –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    return None


def _debug_list_some_files(base: str, limit: int = 3):
    pattern = os.path.join(base, "records500", "**", "*_lr.hea")
    files = glob.glob(pattern, recursive=True)
    print(f"[debug] glob –Ω–∞—à—ë–ª {len(files)} —Ñ–∞–π–ª–æ–≤ –ø–æ —à–∞–±–ª–æ–Ω—É {pattern!r}")
    for p in files[:limit]:
        print("  -", p)


def _extract_one(signal: np.ndarray) -> dict:
    """–¢–∞ –∂–µ —Å—Ö–µ–º–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ (7 —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –Ω–∞ –æ—Ç–≤–µ–¥–µ–Ω–∏–µ)."""
    feats = {}
    L = signal.shape[1]
    for lead in range(L):
        x = signal[:, lead]
        feats.update({
            f"mean_{lead}": float(np.mean(x)),
            f"std_{lead}": float(np.std(x)),
            f"max_{lead}": float(np.max(x)),
            f"min_{lead}": float(np.min(x)),
            f"skew_{lead}": float(skew(x)),
            f"kurt_{lead}": float(kurtosis(x)),
            f"energy_{lead}": float(np.sum(x**2)),
        })
    return feats


def _auto_prepare_dataset():
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞:
    —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç `python scripts/setup_and_train.py --download subset --subset-size 500`
    """
    setup_script = os.path.join(ROOT, "scripts", "setup_and_train.py")
    if not os.path.isfile(setup_script):
        print("–ù–µ –Ω–∞–π–¥–µ–Ω scripts/setup_and_train.py ‚Äî –Ω–µ –º–æ–≥—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å PTB-XL.")
        return False

    cmd = [sys.executable, setup_script, "--download", "subset", "--subset-size", "500"]
    print("–ü—É—Ç—å –∫ PTB-XL –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å–∫–∞—é –∞–≤—Ç–æ-–Ω–∞—Å—Ç—Ä–æ–π–∫—É –¥–∞–Ω–Ω—ã—Ö:")
    print("   ", " ".join(cmd))
    try:
        result = subprocess.run(cmd, cwd=ROOT, check=True)
        return result.returncode == 0
    except subprocess.CalledProcessError as e:
        print(f"–ê–≤—Ç–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π (code={e.returncode}).")
        return False


def main():
    # 1) –∏—â–µ–º –ø—É—Ç—å –∫ PTB-XL (–±–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–∞ ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º)
    base = resolve_base_path(interactive=False)

    # 2) –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV + subset WFDB + –æ–±—É—á–µ–Ω–∏–µ
    if not base:
        ok = _auto_prepare_dataset()
        if not ok:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å PTB-XL –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. "
                  "–ó–∞–ø—É—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é: python scripts/setup_and_train.py --download subset --subset-size 500")
            sys.exit(1)
        # –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç—å —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω –≤ ekg_config.yaml
        base = resolve_base_path(interactive=False)

    if not base:
        print("–ü—É—Ç—å –∫ PTB-XL –≤—Å—ë –µ—â—ë –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω. –ü—Ä–æ–≤–µ—Ä—å ekg_config.yaml –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é PTBXL_PATH.")
        sys.exit(1)

    print(f"base_path: {base}")

    # 3) –µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç ‚Äî –æ–±—É—á–∞–µ–º ¬´–∑–¥–µ—Å—å –∏ —Å–µ–π—á–∞—Å¬ª
    model_path = os.path.join(ROOT, "models", "xgb.pkl")
    if not os.path.isfile(model_path):
        print("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî –æ–±—É—á–∞–µ–º...")
        os.makedirs(os.path.dirname(model_path), exist_ok=True)

        # [1] –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        db, scp = load_metadata(base)
        # [2] –ú–µ—Ç–∫–∏: SCP ‚Üí —Å—É–ø–µ—Ä–∫–ª–∞—Å—Å
        meta = scp_to_superclass(db, scp)
        # [3] –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –Ω–∞–ª–∏—á–∏—é WFDB
        meta = ensure_files_exist(meta, base)
        print(f"  usable records: {len(meta)}")
        if len(meta) == 0:
            print("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö WFDB –∑–∞–ø–∏—Å–µ–π. –ü—Ä–æ–≤–µ—Ä—å –∑–∞–≥—Ä—É–∑–∫—É signals (records500).")
            sys.exit(1)
        # [4] –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤—Å–µ 12 –æ—Ç–≤–µ–¥–µ–Ω–∏–π)
        X, y = build_features(meta, base, leads=None)
        print(f"  X: {X.shape}, classes: {y.value_counts().to_dict()}")
        # [5] –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ
        Xb, yb = balance_undersample(X, y)
        result = train_xgb(Xb, yb)
        result["feature_names"] = list(Xb.columns)
        save_model(result, model_path)
        print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    else:
        print("–ù–∞–π–¥–µ–Ω–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å.")

    # 4) –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –ø–µ—Ä–≤–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
    rec = _first_record_path_from_csv(base)
    if not rec:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∑–∞–ø–∏—Å—å —á–µ—Ä–µ–∑ CSV, –ø—Ä–æ–±—É—é glob...")
        _debug_list_some_files(base)
        # —Å—Ç–∞—Ä—ã–π –∑–∞–ø–∞—Å–Ω–æ–π –ø—É—Ç—å —á–µ—Ä–µ–∑ glob (–º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ fallback)
        pattern = os.path.join(base, "records500", "**", "*_lr.hea")
        import glob
        files = glob.glob(pattern, recursive=True)
        if files:
            rec = files[0][:-4]

    if not rec:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ *_lr.hea –≤ records500/. –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å–∫–∞—á–∞–Ω—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é.")
        return

    bundle = load_model(model_path)
    model = bundle["model"]
    le = bundle["label_encoder"]
    feature_names = bundle.get("feature_names")

    r = wfdb.rdrecord(rec)
    X_one = pd.DataFrame([_extract_one(r.p_signal)])
    if feature_names:
        for col in feature_names:
            if col not in X_one.columns:
                X_one[col] = 0.0
        X_one = X_one[feature_names]

    y_pred = model.predict(X_one)[0]
    label = le.inverse_transform([y_pred])[0]
    label_ru = to_russian(label)
    print(f"üéâ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è {rec}: {label} ‚Äî {label_ru}")

    y_pred = model.predict(X_one)[0]
    label = le.inverse_transform([y_pred])[0]
    print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è {rec}: {label}")


if __name__ == "__main__":
    main()
